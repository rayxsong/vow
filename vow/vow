#!/usr/bin/env python3
# import subprocess
# import sys
from openai import OpenAI
from dotenv import load_dotenv
# import os
# import shlex
# import time
import threading
# import itertools
# import configparser
# import argparse
from usage import menu, get_api_key, get_model, get_os
from spinner import spinner
from run import run_command
from input import get_input

load_dotenv()    

def main():
    menu()
    api_key = get_api_key()
    model = get_model()
    
    client = OpenAI(
        api_key=api_key,
        # api_key= os.getenv("OPENAI_API_KEY"),
    )

    user_input = get_input()
    user_os = get_os()
    if user_input is not None and "exit" in user_input.split():
        exit()

    raw_input = "Give me the command to run:" + user_input + "in" + user_os + "terminal, give me the output directly without any explaination in one line."
    stop_event = threading.Event()
    spinner_thread = threading.Thread(target=spinner, args=(stop_event,))
    spinner_thread.start()

    try:
        completion = client.chat.completions.create(
            messages=[
                {
                    "role": "user",
                    "content": raw_input,
                }
            ],
            model=model,
        )
        raw_output = completion.choices[0].message.content
    except Exception as e:
        print(f"API error: {e}")
        return
    
    stop_event.set()
    spinner_thread.join()
    
    print("The following command will run: ")
    print("================================")
    print(raw_output)
    print("================================")
    print("Are you sure to run? (y/n)")
    if input() == "y":
        print("Here is the result after running:")
        print("================================")
        run_command(raw_output)
        # check if raw_output contains "rm"
        if "rm" in raw_output.split():
            print("Remove excuted.")
    else:
        print("================================")
        print("Command cancelled.")

if __name__ == "__main__":
    main()